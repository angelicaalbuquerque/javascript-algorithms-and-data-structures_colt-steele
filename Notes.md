# Se√ß√£o 1: Big O Notation

> üí° Performance importa.

Assuntos abordados nesta se√ß√£o:

- Necessidade da Nota√ß√£o Big O;
- O que √© Big O Notation;
- Simplificar a Nota√ß√£o Big O;
- Definir "complexidade de tempo" e "complexidade de espa√ßo";
- Avaliar a "complexidade de tempo" e "complexidade de espa√ßo" de um algoritmo usando a Nota√ß√£o Big O;
- Descrever o que √© logaritmo.

### Necessidade da Nota√ß√£o Big O

H√° diversas implementa√ß√µes que s√£o v√°lidas para um mesmo problema. Elas s√£o diferentes, n√£o apenas em nomes e vari√°veis, mas em abordagens tamb√©m. Mas como julgar qual delas √© a melhor? √â disso que trata o Big O.

√â um sistema, √© uma maneira de generalizar o c√≥digo, falar sobre ele e comparar o c√≥digo e seu desempenho com outras partes do c√≥digo. √â como se fosse uma tabela de classifica√ß√£o, com r√≥tulos como "√≥timo", "muito bom", "apenas ok", "eh..." e "terr√≠vel". Entretanto, essa classifica√ß√£o √© feita de forma num√©rica.

Mas por que isso importa? Porque performance importa. Uma implementa√ß√£o de algoritmo pode economizar uma hora toda vez que √© executada em compara√ß√£o com outra implementa√ß√£o. Isso pode ser muito importante para um sistema que √© executado milh√µes de vezes por dia.

Outros motivos da import√¢ncia da nota√ß√£o Big O:

- Ajuda voc√™ a falar melhor sobre seu c√≥digo;
- √â importante ter um vocabul√°rio preciso para falar sobre o desempenho do nosso c√≥digo (√© √∫til entender como sua solu√ß√£o se compara em desempenho com outras);
- √â bom para discutir vantagens e desvantagens entre diferentes abordagens;
- Ao debugar o c√≥digo, ajuda a entender as coisas que est√£o diminuindo a velocidade, n√£o apenas procurar erros, ajudando identificar pontos ineficientes;
- Aparece bastante em entrevistas de emprego.

### Cronometrando nosso c√≥digo

Vamos comparar a efici√™ncia dos c√≥digos abaixo. Ambos escrevem uma fun√ß√£o que calcula a soma de todos os n√∫meros de 1 at√© (e incluindo) algum n√∫mero n.

```js
function addUpTo(n) {
  let total = 0;
  for (let i = 1; i <= n; i++) {
    total += i;
  }
  return total;
}
```

```js
function addUpTo(n) {
  return (n * (n + 1)) / 2;
}
```

Qual √© a melhor? E o que "ser melhor" quer dizer? √â rapidez? √â quanto de mem√≥ria √© usada para guardar os dados cada vez que essa fun√ß√£o √© chamada? Legibilidade?

Geralmente, ser r√°pido e ocupar menos mem√≥ria √© o que costuma ser mais importante, mas costuma tamb√©m prejudicar na legibilidade do c√≥digo.

> üí° √â necess√°rio ter um equil√≠brio entre escrever um bom c√≥digo e escrever um c√≥digo eficiente que n√£o consome muita mem√≥ria e que tamb√©m √© leg√≠vel.

Como eu rotulo o que √© melhor? √â baseado em qu√™?

#### O problema com o tempo

Mesmo testando a performance dos algoritmos, √© preciso saber que:

- _Diferentes_ m√°quinas executam os c√≥digos de forma diferente - as margens podem mudar, as medi√ß√µes reais podem ser diferentes e √© quase garantido que haver√° tempos diferentes;
- A _mesma_ m√°quina executar√° os c√≥digos de forma diferente - o navegador e o sistema operacional podem afetar a velocidade;
- Para algoritmos r√°pidos, as medidas de velocidade podem n√£o ser precisas o suficiente.

Ent√£o, como falamos qual c√≥digo melhor, em termos gerais, sem ter que cronometr√°-lo? N√£o quero fazer um teste para descobrir apenas qual √© o melhor, quero saber qual √© o melhor em termos gerais. E √© a√≠ que entra a Nota√ß√£o Big O.

#### Contando opera√ß√µes

> üí° O tempo sempre ser√° determinado pelo n√∫mero de opera√ß√µes.

Em vez de contar os segundos exatos necess√°rios para a execu√ß√£o do c√≥digo, que podem mudar tanto, o que podemos fazer √© contar v√°rias opera√ß√µes simples que um computador precisa executar, porque isso permanece constante, independentemente de qual computador estamos.

No c√≥digo abaixo, existem apenas tr√™s opera√ß√µes: multiplica√ß√£o, adi√ß√£o e divis√£o, sem importar o tamanho do n√∫mero _n_.

```js
function addUpTo(n) {
  return (n * (n + 1)) / 2;
}
```

Nesta outra solu√ß√£o, existem um pouco mais de opera√ß√µes. Al√©m disso, tem uma vari√°vel _total_ que √© criada e que √© incrementada a cada itera√ß√£o do loop.

```js
function addUpTo(n) {
  let total = 0;
  for (let i = 1; i <= n; i++) {
    total += i;
  }
  return total;
}
```

Ent√£o, a quantidade de opera√ß√µes √© proporcional ao tamanho do n√∫mero _n_. Se _n_ for 20, haver√£o 20 opera√ß√µes. Se _n_ for 100, haver√£o 100 opera√ß√µes. N√£o s√£o apenas 3 opera√ß√µes, s√£o _n_ adi√ß√µes.

Detalhando melhor o n√∫mero de c√°lculos:

<code>total = 0</code>: apenas uma opera√ß√£o;
<code>let i = 1</code>: apenas uma opera√ß√£o;
<code>i <= n</code>: _n_ opera√ß√µes de <code><</code> e _n_ opera√ß√µes de <code>==</code>, totalizando _2n_ opera√ß√µes de compara√ß√£o;
<code>i++</code>: _n_ adi√ß√µes e opera√ß√µes.

Nesse caso, a complexidade √© de 5n+2 (5 opera√ß√µes de n + 2 que est√£o fora do loop), que √© a mesma coisa que dizer que o n√∫mero de opera√ß√µes cresce proporcionalmente ao n√∫mero _n_.

Portanto, se _n_ for 10, haver√£o 52 opera√ß√µes. Se _n_ for 100, haver√£o 502 opera√ß√µes. Se _n_ for 1000, haver√£o 5002 opera√ß√µes.

> üí° A ferramenta [Performance Tracker](https://rithmschool.github.io/function-timer-demo/) ajuda a entender ou tra√ßar o tempo que as fun√ß√µes levam para serem executadas e obter um gr√°fico de desempenho.

### Introdu√ß√£o oficial √† Nota√ß√£o Big O

Big O nos permite falar de uma maneira muito formal sobre como o tempo de execu√ß√£o de um algoritmo cresce √† medida que as entradas aumentam.

√â uma maneira de descrever o relacionamento entre a entrada para uma fun√ß√£o ou √† medida que ela cresce e como isso altera o tempo de execu√ß√£o dessa fun√ß√£o; a rela√ß√£o entre o tamanho da entrada e, em seguida, o tempo relativo a essa entrada.

> üí° Dizemos que um algoritmo √© _O(f(n))_ se o n√∫mero de opera√ß√µes simples a serem executadas for eventualmente menor que uma constante vezes _f(n)_, enquanto _n_ cresce.

Relacionamento de um input de _n_ com o tempo de execu√ß√£o:

- f(n) pode ser linear (f(n) = n) _enquanto n cresce, o tempo de execu√ß√£o cresce linearmente_;
- f(n) pode ser quadr√°tica (f(n) = n¬≤) _enquanto n cresce, o tempo de execu√ß√£o cresce quadraticamente_;
- f(n) pode ser constante (f(n) = 1) _enquanto n cresce, o tempo de execu√ß√£o n√£o cresce e n√£o √© impactado, pois √© sempre constante_;
- f(n) pode ser algo totalmente diferente!

Sendo assim, enquanto _n_ cresce, como isso muda para refletir no tempo de execu√ß√£o?

Exemplos:

1. **Sempre 3 opera√ß√µes: O(1)** - enquanto _n_ cresce √† medida que a entrada para essa fun√ß√£o cresce, isso n√£o reflete no tempo de execu√ß√£o.

```js
function addUpTo(n) {
  return (n * (n + 1)) / 2;
}
```

2. **N√∫mero de opera√ß√µes limitada por m√∫ltiplo de _n_: O(_n_)** - √â uma constante. Enquanto _n_ cresce, o tempo de execu√ß√£o cresce basicamente em propor√ß√£o 1:1 e o n√∫mero de opera√ß√µes √© (eventualmente) limitado por um m√∫ltiplo de _n_. N√£o importa se √© 1n, 5n, 10n... porque no final isso √© simplificado para apenas O(n), pois estamos preocupados apenas com a ordem de magnitude.

```js
function addUpTo(n) {
  let total = 0;
  for (let i = 1; i <= n; i++) {
    total += i;
  }
  return total;
}
```

3. **0(n)** - Na parte "Going up!" do c√≥digo, enquanto o _n_ cresce o loop cresce,ent√£o temos 0(n). O mesmo para a parte "At the top!", que tamb√©m √© 0(n). Sendo assim, √© uma constante e se _n_ triplicar, o templo de execu√ß√£o tamb√©m triplicar√°. Lembrando que n√£o nos preocupamos com quantos _n_ temos, mas sim com o cen√°rio.

```js
function countUpAndDown(n) {
  console.log("Going up!");
  for (var i = 0; i < n; i++) {
    console.log(i);
  }
  console.log("At the top!\nGoing down...");
  for (var j = n - 1; j >= 0; j--) {
    console.log(j);
  }
  console.log("Back down. Bye!");
}
```

4. **Opera√ß√£o O(n) dentro de uma opera√ß√£o O(n): 0(n¬≤)** - Temos um loop aninhado. O primeiro loop √© O(n), pois enquanto _n_ cresce, ter√° um n√∫mero _n_ de opera√ß√µes. O segundo loop √© tamb√©m O(n). Nesse exemplo, n√£o podemos simplificar tudo como O(n) porque os loops est√£o aninhados. Como essa opera√ß√£o √© O(n\*n)- podemos simplificar para O(n¬≤) -, significa que √† medida que _n_ cresce, o tempo de execu√ß√£o cresce proporcionalmente na taxa n¬≤. √â uma quadr√°tica.

```js
function printAllPairs(n) {
  for (var i = 0; i < n; i++) {
    for (var j = 0; j < n; j++) {
      console.log(i, j);
    }
  }
}
```

### Simplificando Express√µes Big O

Conforme vimos em exemplos anteriores, contar opera√ß√µes diferentes pode ser complicado e que a contagem exata realmente n√£o importa, o que importante √© a tend√™ncia geral.

Por exemplo, podemos simplificar numa opera√ß√£o **5n + n** por apenas **n**, j√° que √† medida que **n** cresce, o tempo de execu√ß√£o cresce proporcionalmente e n√£o importa se s√£o duas, tr√™s, dez, vinte, cinquenta vezes.

Existem algumas regras para simplificar express√µes Big O, que s√£o consequ√™ncias da defini√ß√£o de Big O.

- Constantes n√£o importam;

  - Se temos algo como _O(2n)_, simplificamos para _O(n)_.
  - Se temos algo como _O)(500)_, simplificamos para _O(1)_.
  - Se temos algo como _O(13n¬≤)_, simplificamos para _O(n¬≤)_.

- Termos menores tamb√©m n√£o importam.
  - Se temos algo como _O(n + 10)_, simplificamos para _O(n)_.
  - Se temos algo como _O(1000n + 50)_, simplificamos para _O(n)_, n√£o precisamos da constante 1000*n* e nem do termo 50.
  - Se temos algo como _O(n¬≤ + 5n + 8)_, simplificamos para _O(n¬≤)_.

### Big O shorthand

- Analisar a complexidade com Big O pode ser complicado;
- Tem regras pr√°ticas que podem ajudar;
- Essas regras nem sempre ir√£o funcionar, mas s√£o boas para a maioria dos casos.

1. Opera√ß√µes aritm√©ticas s√£o constantes;
   - N√£o importa o tamanho do n√∫mero a ser processado, seu computador leva aproximadamente o mesmo tempo para executar uma opera√ß√£o aritm√©tica, seja 2 + 2 ou 1 milh√£o + 2.
2. Atribui√ß√£o de vari√°vel tamb√©m √© constante;
   - O computador leva o mesmo tempo para criar uma vari√°vel que voc√™ sabe que X √© igual a 5, ou que X √© igual a 1 milh√£o.
3. Acessar elementos em um array (por index) ou objeto (por chave) √© uma opera√ß√£o constante;
   - O computador leva o mesmo tempo para acessar o primeiro elemento de um array ou o √∫ltimo elemento de um array.
4. Em um loop, a complexidade √© a dura√ß√£o do loop vezes a complexidade de qualquer opera√ß√£o que aconte√ßa dentro do loop;
   - Se voc√™ tem um loop aninhado, e o loop externo tem complexidade O(n) e o loop interno tem complexidade O(n¬≤), ent√£o o loop externo √© O(n¬≤).

No gr√°fico abaixo, vemos com clareza a diferen√ßa entre as complexidades. Perceba que O(1) √© sempre uma constante em linha reta, enquanto O(n) cresce de acordo com o tamanho do _n_.

<div align="left">
    <img src=".github/01-general-trend.png" width="500"/>
</div>

### Complexidade de Espa√ßo

> üí° Complexidade de Espa√ßo √© o espa√ßo sobre a quantidade de mem√≥ria que um algoritmo usa.

At√© agora, nos preocupamos apenas com a complexidade do tempo, sobre a rapidez com que os algoritmos s√£o executados com o tempo de execu√ß√£o ‚Äî Analisamos o tempo de execu√ß√£o de um algoritmo conforme o tamanho da entrada aumenta.

Mas tamb√©m podemos nos preocupar com a complexidade do espa√ßo, que √© o que acontece com o espa√ßo que um algoritmo ocupa √† medida que o tamanho da entrada aumenta. Quanto de mem√≥ria adicional precisamos alocar para executar o c√≥digo em nosso algoritmo?

√Ä medida que _n_ cresce, assumimos que o resultado final vai crescer. Portanto, n√£o vamos nos preocupar com esse espa√ßo, vamos nos preocupar com as repercuss√µes que t√™m dentro do algoritmo, o que acontece dentro do algoritmo.

**Regras b√°sicas**:

- A maioria dos primitivos (booleans, numbers, undefined, null) s√£o constantes, ou seja, ocupam um espa√ßo fixo na mem√≥ria;
- Strings ocupam um espa√ßo de mem√≥ria proporcional ao tamanho da string, sendo assim, requerem um espa√ßo O(_n_), onde _n_ √© o tamanho da string;
- Tipos de refer√™ncia s√£o, geralmente, O(_n_), onde _n_ √© o tamanho do array (para arrays) ou o n√∫mero de chaves (no objeto).

Observando um exemplo para analisar a complexidade de espa√ßo:

```js
function sum(arr) {
  let total = 0;
  for (let i = 0; i < arr.length; i++) {
    total += arr[i];
  }
  return total;
}
```

Bem, n√£o importa qual seja o comprimento do array, temos uma vari√°vel chamada _total_ (1 n√∫mero) e ent√£o estamos fazendo um _loop_, que tem uma segunda declara√ß√£o dentro dele (outro n√∫mero).

Essa fun√ß√£o s√≥ tem duas vari√°veis e n√£o estamos adicionando novas vari√°veis com base no comprimento do array. Isso significa que temos um espa√ßo constante, ou seja, O(1).

Outro exemplo:

```js
function double(arr) {
  let newArr = [];
  for (let i = 0; i < arr.length; i++) {
    newArr.push(2 * arr[i]);
  }
  return newArr;
}
```

√Ä medida que o comprimento do array cresce, o comprimento do novo array (uma matriz) tamb√©m cresce. Na linha <code>let newArr = [] </code> vamos criar uma nova matriz, mas isso n√£o √© t√£o significativo quanto <code>newArr.push(2 \* arr[i]);</code>, onde temos essa nova matriz e ela est√° ficando cada vez mais longa diretamente na propor√ß√£o do comprimento da entrada. Logo, se a matriz tiver 10 itens, estamos armazenando 10 itens em uma nova matriz.

Sendo assim, o espa√ßo ocupado ser√° diretamente proporcional ao tamanho da entrada, ou seja, O(_n_).

### Logs

Vimos at√© aqui algumas complexidades comuns: O(1), O(_n_) e O(_n¬≤_). Entretanto, algumas vezes express√µes big O envolvem express√µes matem√°ticas mais complexas. Uma das que aparecem com muita frequ√™ncia √© o logaritmo.

Em vez da complexidade do tempo desses algoritmos terminar em O(_n_), eles podem terminar em O(log _n_).

#### O que √© logaritmo?

Assim como divis√£o e multiplica√ß√£o s√£o um par, logaritmo e exponencia√ß√£o s√£o tamb√©m um par. O logaritmo √© o inverso da exponencia√ß√£o.

Exemplo:

<code>Log2(8) = 3</code>

A leitura √© feita como logaritmo de 8 na base 2 √© igual a 3. E o que estamos calculando √© que se elevarmos 2 a algo, que algo √© esse que nos dar√° 8?

A resposta √© 3. Se elevarmos 2 ao cubo, obteremos 8 (2¬≥ = 8). Logo:

<code>log2(valor) = expoente</code> √â respondido por <code>2^expoente = valor</code>.

> üí° A base do logaritmo nem sempre √© 2. Podemos ter logaritmos na base 10, na base 3, na base 5, etc. Mas a base 2 √© a mais comum. Podemos omitir o 2 da f√≥rmula, j√° que √© a base mais comum, ent√£o podemos escrever apenas <code>log</code>.

> üí° O logaritmo de um numero aproximadamente mede o n√∫mero de vezes que voc√™ pode dividir esse n√∫mero por 2 **antes de chegar a um valor que √© menor ou igual a 1**.

Ent√£o, se tivermos um 8, dividiremos por 2 e ainda ser√° maior que 1 (4). Se dividirmos de novo, continuar√° maior que 1 (2). Ent√£o alcan√ßamos o valor 1, e n√£o podemos dividir mais. Ent√£o, o logaritmo de 8 √© 3.

Vejamos melhor o exemplo:

<div align="left">
    <img src=".github/02-log.png" width="500"/>
</div>

Entretanto, o c√°lculo exato n√£o √© t√£o importante. O que importa √© que, se olharmos para o gr√°fico anteriormente mostrado aqui, podemos perceber que a complexidade de tempo logar√≠tmica √© √≥tima! Depois da constante O(1), √© a melhor complexidade de tempo que podemos ter.

#### Por que isso importa?

- Certos algoritmos t√™m complexidade de tempo logar√≠tmica;
- Algoritmos de ordena√ß√£o eficientes envolvem logaritmos;
- Recurs√£o √†s vezes envolve complexidade de espa√ßo logar√≠tmica.

### üìå Recapitula√ß√£o Nota√ß√£o Big O

- Para analisar o desempenho de um algoritmo, n√≥s utilizamos Nota√ß√£o Big O;
  - _Queremos saber como o tempo muda ou como a complexidade do espa√ßo muda √† medida que o tamanho da entrada aumenta._
- Big O pode nos dar um entendimento de alto n√≠vel de complexidade de tempo ou espa√ßo de um algoritmo;
- Nota√ß√£o Big O n√£o liga para precis√£o, apenas para tend√™ncias gerais (linear? quadr√°tica? constante?);
- A complexidade do espa√ßo ou tempo, medida pelo Big O, depende apenas do algoritmo e n√£o do hardware que utilizamos para execut√°-lo;
- Big O est√° em todo lugar e precisamos praticar.

# Se√ß√£o 2: An√°lise de performance de arrays e objetos

Agora que j√° vimos Big O, vamos analisar coisas b√°sicas que fazemos o tempo inteiro em JS: arrays, objetos e m√©todos built-in. Como √© a performance? Qual m√©todo pode ser mais lento? Quais s√£o as coisas mais r√°pidas que podemos fazer com um array?

Objetivos desta se√ß√£o:

- Entender como objetos e arrays trabalham, atrav√©s das lentes do Big O;
- Explicar por que adicionar elementos ao in√≠cio de um array √© custoso;
- Comparar e contrastra o tempo de execu√ß√£o de arrays e objetos, assim como m√©todos built-in (como forEach e Object.keys()...).

### The Big O de objetos

Objetos s√£o estruturas de dados n√£o ordenadas e tudo √© armazenado em pares de valores-chave. Exemplo:

```js
let instructor = {
  firstName: "Kelly",
  isInstructor: true,
  favoriteNumbers: [1, 2, 3, 4],
};
```

#### Quando utilizar objetos:

- Quando n√£o precisamos de ordem, objetos s√£o uma escolha excelente;
- Quando precisamos de r√°pido acesso / inser√ß√£o e remo√ß√£o.

Quando falamos em rapidez, estamos falando de tempo constante para quase todas as a√ß√µes:

- Inser√ß√£o: O(1);
- Remo√ß√£o: O(1);
- Busca: O(N);
- Acesso: O(1).

O tempo de busca √© O(N) porque, para buscar um valor, precisamos percorrer todo o objeto para ver se aquele valor existe. E se potencialmente o n√∫mero de propriedades cresce √† medida que N cresce, logo cresce a quantidade de tempo que leva para fazer essa busca. Entretanto, se quisermos acessar um valor, o tempo de acesso √© O(1), pois n√£o precisamos percorrer todo o objeto para encontrar aquele valor.

#### Big O de m√©todos de objetos

- Object.keys: O(N);
  - _Retorna todas as chaves de um objeto. O(N) porque precisamos percorrer todo o objeto para encontrar todas as chaves._
- Object.values: O(N);
  - _Retorna todos os valores de um objeto. O(N) porque precisamos percorrer todo o objeto para encontrar todos os valores._
- Object.entries: O(N);
  - _Retorna um array de arrays contendo todas as chaves e valores de um objeto. O(N) porque precisamos percorrer todo o objeto para encontrar todas as chaves e valores, o que torna esse m√©todo mais trabalhoso._
- hasOwnProperty: O(1).
  - _Verifica se um objeto possui uma determinada chave. O(1) porque n√£o precisamos percorrer todo o objeto para encontrar a chave._

### Arrays atrav√©s das lentes do Big O

O grande ponto dos arrays √© que elas s√£o ordenadas, diferentemente dos objetos, que n√£o s√£o. Isso √© muito √∫til, mas pode ter custos para algumas das opera√ß√µes.

Quando utilizar arrays:

- Quando precisamos de ordem, arrays s√£o uma escolha excelente;
- Quando precisamos de acesso r√°pido / inser√ß√£o e remo√ß√£o (em certas situa√ß√µes).

#### Big O de arrays

- Inser√ß√£o: depende;
  - _Se inserirmos um elemento no final do array, o tempo de inser√ß√£o √© O(1). Mas se inserirmos um elemento no in√≠cio do array, o tempo de inser√ß√£o √© O(N), pois tem rela√ß√£o com a quantidade de √≠ndices, que precisar√£o ser reindexados. Exemplo: let names = ["Michael", "Ana", "Eric"]. Se eu inserir "Gustavo" no in√≠cio, os outros nomes n√£o ocupar√£o mais os √≠ndices 0, 1 e 2, respectivamente, precisando ser reindexados._
- Remo√ß√£o: depende;
  - _Se removermos um elemento do final do array, o tempo de remo√ß√£o √© O(1). Mas se removermos um elemento do in√≠cio do array, o tempo de remo√ß√£o √© O(N), pois os √≠ndices precisar√£o ser reindexados._
- Busca: O(N);
  - _Para buscar um elemento em um array, precisamos percorrer todo o array para encontrar aquele elemento. E se potencialmente o n√∫mero de elementos cresce √† medida que N cresce, logo cresce a quantidade de tempo que leva para fazer essa busca._
- Acesso: O(1).
  - _Para acessar um elemento em um array, o tempo de acesso √© O(1), pois n√£o precisamos percorrer todo o array para encontrar aquele elemento, podemos pular imediatamente para o index, independentemente do tamanho do array._

> üí° push() e pop() s√£o m√©todos que adicionam e removem elementos do final do array, respectivamente, e s√£o mais r√°pidos que shift() e unshift(), m√©todos que adicionam e removem elementos do in√≠cio do array, respectivamente.

#### Big O de m√©todos de arrays

- push: O(1);
  - _Adiciona um elemento ao final do array. O(1) porque n√£o precisamos percorrer todo o array para encontrar o final, podemos pular imediatamente para o √∫ltimo index, independentemente do tamanho do array._
- pop: O(1);
  - _Remove um elemento do final do array. O(1) porque n√£o precisamos percorrer todo o array para encontrar o final, podemos pular imediatamente para o √∫ltimo index, independentemente do tamanho do array._
- shift: O(N);
  - _Remove um elemento do in√≠cio do array. O(N) porque os √≠ndices precisar√£o ser reindexados._
- unshift: O(N);
  - _Adiciona um elemento ao in√≠cio do array. O(N) porque os √≠ndices precisar√£o ser reindexados._
- concat: O(N);
  - _Concatena dois arrays. O(N) porque √† medida que os arrays crescem, o tempo vai demorar e crescer proporcionalmente ao tamanho total do novo array. Tecnicamente, poder√≠amos argumentar que a complexidade deveria ser O(N + m), onde m √© o tamanho do novo array, mas O(N) j√° serve._
- slice: O(N);
  - _Retorna uma c√≥pia de uma parte de um array. O(N) porque se tentarmos copiar 10 elementos vs 1000 elementos de um array, a quantidade de tempo ir√° aumentar proporcionalmente ao tamanho da c√≥pia ou de quantos elementos estamos tentando copiar._
- splice: O(N);
  - _Remove e/ou adiciona elementos de um array e, opcionalmente, os substitui por outros elementos. O(N) porque vai ser preciso reindexar os elementos._
- sort: O(N \* log N);
  - _Ordena os elementos de um array. O(N \* log N) porque o algoritmo de ordena√ß√£o √© baseado em compara√ß√µes, e o tempo de compara√ß√£o √© O(log N)._
- forEach/map/filter/reduce/etc: O(N);
  - _Esses m√©todos iteram sobre cada elemento de um array. O(N) porque eles est√£o fazendo looping sobre cada elemento ou fazendo algo para cada elemento, seja um teste booleano ou apenas imprimindo o que estamos fazendo, isso envolve atuar em cada elemento ou com cada elemento. Assim, √† medida que o tamanho do array aumenta, aumenta a quantidade de tempo que leva para percorr√™-lo._

### üìå Recapitula√ß√£o Arrays e Objetos

- Quase tudo o que podemos fazer com arrays, todos os m√©todos incorporados, tem complexidade O(N);
- Ordena√ß√£o √© o mais lento, O(N \* log N);
- Os m√©todos push e pop s√£o costantes, O(1), super r√°pidos;
- Objetos s√£o r√°pidos em praticamente tudo, mas n√£o h√° ordem para os arrays, que s√£o √≥timos quando voc√™ precisa de ordena√ß√£o;
- Arrays s√£o √≥timos para ordena√ß√£o, mas lembre-se que √© melhor se voc√™ puder fazer adi√ß√µes e remo√ß√µes no final do array, pois √© mais r√°pido do que no in√≠cio;
- Adicionar/remover algo tanto no come√ßo quanto no meio de um array causa um efeito cascata de reindexa√ß√£o.

# Se√ß√£o 3: Abordagem de Resolu√ß√£o de Problemas

> üí° Muitas das estrat√©gias que vamos discutir s√£o baseadas no livro **_How To Solve It_**, de George Polya.

Quando encaramos um problema de c√≥digo para resolver, √© importante que tenhamos uma abordagem para resolver esse problema. Que passos podemos seguir para torn√°-lo resolvido?

_Esta primeira se√ß√£o √© mais sobre a abordagem b√°sica para resolver um problema que voc√™ n√£o sabe resolver. Passos que voc√™ pode dar, etapas para torn√°-lo mais f√°cil. A segunda se√ß√£o que vem depois dessa √© mais focada em c√≥digo e √© sobre projetos espec√≠ficos e pequenas estrat√©gias para resolver problemas._

Objetos da se√ß√£o:

- Defini√ß√£o de algoritmo;
- Elaborar um plano para resolver algoritmos;
- Comparar e contrastar padr√µes de resolu√ß√µes de problemas, incluindo contadores de frequ√™ncia, dividir e conquistar e t√©cnica two pointers.

### O que √© um algoritmo?

Um **processo** ou um **conjunto de etapas** para realizar uma determinada tarefa.

Por que √© importante saber disso?

- Quase tudo o que voc√™ faz em programa√ß√£o envolve algum tipo de algoritmo, sejam coisas super b√°sicas ou um aplicativo complexo;
- √â o fundamento para ser um solucionador de problemas de sucesso e um bom programador.

Como melhorar suas habilidades?

- Estabele√ßa um plano para resolver problemas;
- Domine os padr√µes comuns de resolu√ß√£o de problemas.

### Estrat√©gias de resolu√ß√£o de problemas

- 1. Entenda o problema;
- 2. Explore exemplos concretos;
- 3. Quebre-o em partes menores;
- 4. Resolva/simplifique o problema;
- 5. Olha para tr√°s, refatore e melhore o c√≥digo.

Nesta se√ß√£o, vamos explorar cada uma dessas etapas em detalhes.

## Passo 1) Entenda o problema

_Voc√™ pode criar um aplicativo copiando um passo a passo e copiar o c√≥digo de outras pessoas. Mas quando se trata de resolver problemas novos e novos desafios, a coisa fica mais dif√≠cil._

_Voc√™ melhora isso com o tempo, independentemente das tecnologias que voc√™ usa, da linguagem em que est√° trabalhando, √© realmente importante ter um forte conjunto de habilidades para resolver problemas. E muito disso vir√° naturalmente com o tempo, mas vale a pena ser deliberado, vale a pena ter um plano. Esse plano n√£o vai resolver seus problemas, mas vai ajud√°-lo a pensar para resolv√™-lo e ajudar as solu√ß√µes surgirem de maneira mais natural._

Antes de come√ßar a sair codando ou tentar resolver o problema, √© importante dar um passo atr√°s e garantir que voc√™ entende a tarefa que est√° √† sua frente. O que voc√™ est√° tentando resolver? O que voc√™ est√° tentando fazer? O que voc√™ est√° tentando construir?

Tem diversas perguntas que voc√™ pode fazer para ajudar a garantir que voc√™ entenda o problema:

1. Voc√™ pode reafirmar o problema com suas pr√≥prias palavras?
   - _Apenas certifique-se de que voc√™ pode reformular novamente a pergunta. Mude um pouco, com suas pr√≥prias palavras, para garantir que voc√™ realmente entenda a pergunta._
2. Quais s√£o as entradas que o problema requer?
   - _Quais s√£o os dados que voc√™ precisa para resolver o problema._
3. Quais s√£o as sa√≠das que devem vir da solu√ß√£o do problema?
   - _Quais s√£o os resultados que voc√™ precisa gerar ao resolver o problema._
4. As sa√≠das podem ser determinadas a partir das entradas? Em outras palavras, voc√™ tem todas as informa√ß√µes necess√°rias para resolver o problema?
5. Como devo rotular as pe√ßas importantes de dados que s√£o parte do problema?
   - _Qual a terminologia que voc√™ deve usar._
