# Se√ß√£o 1: Big O Notation

> üí° Performance importa.

Assuntos abordados nesta se√ß√£o:

- Necessidade da Nota√ß√£o Big O;
- O que √© Big O Notation;
- Simplificar a Nota√ß√£o Big O;
- Definir "complexidade de tempo" e "complexidade de espa√ßo";
- Avaliar a "complexidade de tempo" e "complexidade de espa√ßo" de um algoritmo usando a Nota√ß√£o Big O;
- Descrever o que √© logaritmo.

### Necessidade da Nota√ß√£o Big O

H√° diversas implementa√ß√µes que s√£o v√°lidas para um mesmo problema. Elas s√£o diferentes, n√£o apenas em nomes e vari√°veis, mas em abordagens tamb√©m. Mas como julgar qual delas √© a melhor? √â disso que trata o Big O.

√â um sistema, √© uma maneira de generalizar o c√≥digo, falar sobre ele e comparar o c√≥digo e seu desempenho com outras partes do c√≥digo. √â como se fosse uma tabela de classifica√ß√£o, com r√≥tulos como "√≥timo", "muito bom", "apenas ok", "eh..." e "terr√≠vel". Entretanto, essa classifica√ß√£o √© feita de forma num√©rica.

Mas por que isso importa? Porque performance importa. Uma implementa√ß√£o de algoritmo pode economizar uma hora toda vez que √© executada em compara√ß√£o com outra implementa√ß√£o. Isso pode ser muito importante para um sistema que √© executado milh√µes de vezes por dia.

Outros motivos da import√¢ncia da nota√ß√£o Big O:

- Ajuda voc√™ a falar melhor sobre seu c√≥digo;
- √â importante ter um vocabul√°rio preciso para falar sobre o desempenho do nosso c√≥digo (√© √∫til entender como sua solu√ß√£o se compara em desempenho com outras);
- √â bom para discutir vantagens e desvantagens entre diferentes abordagens;
- Ao debugar o c√≥digo, ajuda a entender as coisas que est√£o diminuindo a velocidade, n√£o apenas procurar erros, ajudando identificar pontos ineficientes;
- Aparece bastante em entrevistas de emprego.

### Cronometrando nosso c√≥digo

Vamos comparar a efici√™ncia dos c√≥digos abaixo. Ambos escrevem uma fun√ß√£o que calcula a soma de todos os n√∫meros de 1 at√© (e incluindo) algum n√∫mero n.

```js
function addUpTo(n) {
  let total = 0;
  for (let i = 1; i <= n; i++) {
    total += i;
  }
  return total;
}
```

```js
function addUpTo(n) {
  return (n * (n + 1)) / 2;
}
```

Qual √© a melhor? E o que "ser melhor" quer dizer? √â rapidez? √â quanto de mem√≥ria √© usada para guardar os dados cada vez que essa fun√ß√£o √© chamada? Legibilidade?

Geralmente, ser r√°pido e ocupar menos mem√≥ria √© o que costuma ser mais importante, mas costuma tamb√©m prejudicar na legibilidade do c√≥digo.

> üí° √â necess√°rio ter um equil√≠brio entre escrever um bom c√≥digo e escrever um c√≥digo eficiente que n√£o consome muita mem√≥ria e que tamb√©m √© leg√≠vel.

Como eu rotulo o que √© melhor? √â baseado em qu√™?

#### O problema com o tempo

Mesmo testando a performance dos algoritmos, √© preciso saber que:

- _Diferentes_ m√°quinas executam os c√≥digos de forma diferente - as margens podem mudar, as medi√ß√µes reais podem ser diferentes e √© quase garantido que haver√° tempos diferentes;
- A _mesma_ m√°quina executar√° os c√≥digos de forma diferente - o navegador e o sistema operacional podem afetar a velocidade;
- Para algoritmos r√°pidos, as medidas de velocidade podem n√£o ser precisas o suficiente.

Ent√£o, como falamos qual c√≥digo melhor, em termos gerais, sem ter que cronometr√°-lo? N√£o quero fazer um teste para descobrir apenas qual √© o melhor, quero saber qual √© o melhor em termos gerais. E √© a√≠ que entra a Nota√ß√£o Big O.

#### Contando opera√ß√µes

> üí° O tempo sempre ser√° determinado pelo n√∫mero de opera√ß√µes.

Em vez de contar os segundos exatos necess√°rios para a execu√ß√£o do c√≥digo, que podem mudar tanto, o que podemos fazer √© contar v√°rias opera√ß√µes simples que um computador precisa executar, porque isso permanece constante, independentemente de qual computador estamos.

No c√≥digo abaixo, existem apenas tr√™s opera√ß√µes: multiplica√ß√£o, adi√ß√£o e divis√£o, sem importar o tamanho do n√∫mero _n_.

```js
function addUpTo(n) {
  return (n * (n + 1)) / 2;
}
```

Nesta outra solu√ß√£o, existem um pouco mais de opera√ß√µes. Al√©m disso, tem uma vari√°vel _total_ que √© criada e que √© incrementada a cada itera√ß√£o do loop.

```js
function addUpTo(n) {
  let total = 0;
  for (let i = 1; i <= n; i++) {
    total += i;
  }
  return total;
}
```

Ent√£o, a quantidade de opera√ß√µes √© proporcional ao tamanho do n√∫mero _n_. Se _n_ for 20, haver√£o 20 opera√ß√µes. Se _n_ for 100, haver√£o 100 opera√ß√µes. N√£o s√£o apenas 3 opera√ß√µes, s√£o _n_ adi√ß√µes.

Detalhando melhor o n√∫mero de c√°lculos:

<code>total = 0</code>: apenas uma opera√ß√£o;
<code>let i = 1</code>: apenas uma opera√ß√£o;
<code>i <= n</code>: _n_ opera√ß√µes de <code><</code> e _n_ opera√ß√µes de <code>==</code>, totalizando _2n_ opera√ß√µes de compara√ß√£o;
<code>i++</code>: _n_ adi√ß√µes e opera√ß√µes.

Nesse caso, a complexidade √© de 5n+2 (5 opera√ß√µes de n + 2 que est√£o fora do loop), que √© a mesma coisa que dizer que o n√∫mero de opera√ß√µes cresce proporcionalmente ao n√∫mero _n_.

Portanto, se _n_ for 10, haver√£o 52 opera√ß√µes. Se _n_ for 100, haver√£o 502 opera√ß√µes. Se _n_ for 1000, haver√£o 5002 opera√ß√µes.

> üí° A ferramenta [Performance Tracker](https://rithmschool.github.io/function-timer-demo/) ajuda a entender ou tra√ßar o tempo que as fun√ß√µes levam para serem executadas e obter um gr√°fico de desempenho.

### Introdu√ß√£o oficial √† Nota√ß√£o Big O

Big O nos permite falar de uma maneira muito formal sobre como o tempo de execu√ß√£o de um algoritmo cresce √† medida que as entradas aumentam.

√â uma maneira de descrever o relacionamento entre a entrada para uma fun√ß√£o ou √† medida que ela cresce e como isso altera o tempo de execu√ß√£o dessa fun√ß√£o; a rela√ß√£o entre o tamanho da entrada e, em seguida, o tempo relativo a essa entrada.

> üí° Dizemos que um algoritmo √© _O(f(n))_ se o n√∫mero de opera√ß√µes simples a serem executadas for eventualmente menor que uma constante vezes _f(n)_, enquanto _n_ cresce.

Relacionamento de um input de _n_ com o tempo de execu√ß√£o:

- f(n) pode ser linear (f(n) = n) _enquanto n cresce, o tempo de execu√ß√£o cresce linearmente_;
- f(n) pode ser quadr√°tica (f(n) = n¬≤) _enquanto n cresce, o tempo de execu√ß√£o cresce quadraticamente_;
- f(n) pode ser constante (f(n) = 1) _enquanto n cresce, o tempo de execu√ß√£o n√£o cresce e n√£o √© impactado, pois √© sempre constante_;
- f(n) pode ser algo totalmente diferente!

Sendo assim, enquanto _n_ cresce, como isso muda para refletir no tempo de execu√ß√£o?

Exemplos:

1. **Sempre 3 opera√ß√µes: O(1)** - enquanto _n_ cresce √† medida que a entrada para essa fun√ß√£o cresce, isso n√£o reflete no tempo de execu√ß√£o.

```js
function addUpTo(n) {
  return (n * (n + 1)) / 2;
}
```

2. **N√∫mero de opera√ß√µes limitada por m√∫ltiplo de _n_: O(_n_)** - √â uma constante. Enquanto _n_ cresce, o tempo de execu√ß√£o cresce basicamente em propor√ß√£o 1:1 e o n√∫mero de opera√ß√µes √© (eventualmente) limitado por um m√∫ltiplo de _n_. N√£o importa se √© 1n, 5n, 10n... porque no final isso √© simplificado para apenas O(n), pois estamos preocupados apenas com a ordem de magnitude.

```js
function addUpTo(n) {
  let total = 0;
  for (let i = 1; i <= n; i++) {
    total += i;
  }
  return total;
}
```

3. **0(n)** - Na parte "Going up!" do c√≥digo, enquanto o _n_ cresce o loop cresce,ent√£o temos 0(n). O mesmo para a parte "At the top!", que tamb√©m √© 0(n). Sendo assim, √© uma constante e se _n_ triplicar, o templo de execu√ß√£o tamb√©m triplicar√°. Lembrando que n√£o nos preocupamos com quantos _n_ temos, mas sim com o cen√°rio.

```js
function countUpAndDown(n) {
  console.log("Going up!");
  for (var i = 0; i < n; i++) {
    console.log(i);
  }
  console.log("At the top!\nGoing down...");
  for (var j = n - 1; j >= 0; j--) {
    console.log(j);
  }
  console.log("Back down. Bye!");
}
```

4. **Opera√ß√£o O(n) dentro de uma opera√ß√£o O(n): 0(n¬≤)** - Temos um loop aninhado. O primeiro loop √© O(n), pois enquanto _n_ cresce, ter√° um n√∫mero _n_ de opera√ß√µes. O segundo loop √© tamb√©m O(n). Nesse exemplo, n√£o podemos simplificar tudo como O(n) porque os loops est√£o aninhados. Como essa opera√ß√£o √© O(n\*n)- podemos simplificar para O(n¬≤) -, significa que √† medida que _n_ cresce, o tempo de execu√ß√£o cresce proporcionalmente na taxa n¬≤. √â uma quadr√°tica.

```js
function printAllPairs(n) {
  for (var i = 0; i < n; i++) {
    for (var j = 0; j < n; j++) {
      console.log(i, j);
    }
  }
}
```

### Simplificando Express√µes Big O

Conforme vimos em exemplos anteriores, contar opera√ß√µes diferentes pode ser complicado e que a contagem exata realmente n√£o importa, o que importante √© a tend√™ncia geral.

Por exemplo, podemos simplificar numa opera√ß√£o **5n + n** por apenas **n**, j√° que √† medida que **n** cresce, o tempo de execu√ß√£o cresce proporcionalmente e n√£o importa se s√£o duas, tr√™s, dez, vinte, cinquenta vezes.

Existem algumas regras para simplificar express√µes Big O, que s√£o consequ√™ncias da defini√ß√£o de Big O.

- Constantes n√£o importam;

  - Se temos algo como _O(2n)_, simplificamos para _O(n)_.
  - Se temos algo como _O)(500)_, simplificamos para _O(1)_.
  - Se temos algo como _O(13n¬≤)_, simplificamos para _O(n¬≤)_.

- Termos menores tamb√©m n√£o importam.
  - Se temos algo como _O(n + 10)_, simplificamos para _O(n)_.
  - Se temos algo como _O(1000n + 50)_, simplificamos para _O(n)_, n√£o precisamos da constante 1000*n* e nem do termo 50.
  - Se temos algo como _O(n¬≤ + 5n + 8)_, simplificamos para _O(n¬≤)_.

### Big O shorthand

- Analisar a complexidade com Big O pode ser complicado;
- Tem regras pr√°ticas que podem ajudar;
- Essas regras nem sempre ir√£o funcionar, mas s√£o boas para a maioria dos casos.

1. Opera√ß√µes aritm√©ticas s√£o constantes;
   - N√£o importa o tamanho do n√∫mero a ser processado, seu computador leva aproximadamente o mesmo tempo para executar uma opera√ß√£o aritm√©tica, seja 2 + 2 ou 1 milh√£o + 2.
2. Atribui√ß√£o de vari√°vel tamb√©m √© constante;
   - O computador leva o mesmo tempo para criar uma vari√°vel que voc√™ sabe que X √© igual a 5, ou que X √© igual a 1 milh√£o.
3. Acessar elementos em um array (por index) ou objeto (por chave) √© uma opera√ß√£o constante;
   - O computador leva o mesmo tempo para acessar o primeiro elemento de um array ou o √∫ltimo elemento de um array.
4. Em um loop, a complexidade √© a dura√ß√£o do loop vezes a complexidade de qualquer opera√ß√£o que aconte√ßa dentro do loop;
   - Se voc√™ tem um loop aninhado, e o loop externo tem complexidade O(n) e o loop interno tem complexidade O(n¬≤), ent√£o o loop externo √© O(n¬≤).

No gr√°fico abaixo, vemos com clareza a diferen√ßa entre as complexidades. Perceba que O(1) √© sempre uma constante em linha reta, enquanto O(n) cresce de acordo com o tamanho do _n_.

<div align="left">
    <img src=".github/01-general-trend.png" width="500"/>
</div>

### Complexidade de Espa√ßo

> üí° Complexidade de Espa√ßo √© o espa√ßo sobre a quantidade de mem√≥ria que um algoritmo usa.

At√© agora, nos preocupamos apenas com a complexidade do tempo, sobre a rapidez com que os algoritmos s√£o executados com o tempo de execu√ß√£o ‚Äî Analisamos o tempo de execu√ß√£o de um algoritmo conforme o tamanho da entrada aumenta.

Mas tamb√©m podemos nos preocupar com a complexidade do espa√ßo, que √© o que acontece com o espa√ßo que um algoritmo ocupa √† medida que o tamanho da entrada aumenta. Quanto de mem√≥ria adicional precisamos alocar para executar o c√≥digo em nosso algoritmo?

√† medida que _n_ cresce, assumimos que o resultado final vai crescer Portanto, n√£o vamos nos preocupar com esse espa√ßo, vamos nos preocupar com as repercuss√µes que t√™m dentro do algoritmo, o que acontece dentro do algoritmo.

**Regras b√°sicas**:

- A maioria dos primitivos (booleans, numbers, undefined, null) s√£o constantes, ou seja, ocupam um espa√ßo fixo na mem√≥ria;
- Strings ocupam um espa√ßo de mem√≥ria proporcional ao tamanho da string, sendo assim, requerem um espa√ßo O(_n_), onde _n_ √© o tamanho da string;
- Tipos de refer√™ncia s√£o, geralmente, O(_n_), onde _n_ √© o tamanho do array (para arrays) ou o n√∫mero de chaves (no objeto).

Observando um exemplo para analisar a complexidade de espa√ßo:

```js
function sum(arr) {
  let total = 0;
  for (let i = 0; i < arr.length; i++) {
    total += arr[i];
  }
  return total;
}
```

Bem, n√£o importa qual seja o comprimento do array, temos uma vari√°vel chamada _total_ (1 n√∫mero) e ent√£o estamos fazendo um _loop_, que tem uma segunda declara√ß√£o dentro dele (outro n√∫mero).

Essa fun√ß√£o s√≥ tem duas vari√°veis e n√£o estamos adicionando novas vari√°veis com base no comprimento do array. Isso significa que temos um espa√ßo constante, ou seja, O(1).

Outro exemplo:

```js
function double(arr) {
  let newArr = [];
  for (let i = 0; i < arr.length; i++) {
    newArr.push(2 * arr[i]);
  }
  return newArr;
}
```

√Ä medida que o comprimento do array cresce, o comprimento do novo array (uma matriz) tamb√©m cresce. Na linha <code>let newArr = [] </code> vamos criar uma nova matriz, mas isso n√£o √© t√£o significativo quanto <code>newArr.push(2 \* arr[i]);</code>, onde temos essa nova matriz e ela est√° ficando cada vez mais longa diretamente na propor√ß√£o do comprimento da entrada. Logo, se a matriz tiver 10 itens, estamos armazenando 10 itens em uma nova matriz.

Sendo assim, o espa√ßo ocupado ser√° diretamente proporcional ao tamanho da entrada, ou seja, O(_n_).

<!-- ### Logs e Recapitula√ß√£o -->
